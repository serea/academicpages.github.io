---
title: '金融领域的纵向联邦学习探索'
date: 2021-07-20
permalink: /posts/2021/07/verticalfd/
tags:
  - 联邦学习
  - 实习总结
---


纵向联邦学习

***纵向联邦学习定义***

依据联邦学习的不同参与方持有数据的特点不同，可以将其分类为横向联邦学习、纵向联邦学习以及联邦迁移学习等。横向的联邦学习是样本的分割，由于其良好的特性可以设计出较为通用的联邦学习方案。而更为困难且在业界得到很多应用的是纵向联邦学习，其特点是不同数据持有方具备的是同一样本（往往是某个客户）的不同特征维度，这是由于不同的公司业务不同造成的。在风控场景中纵向联邦学习得到了更为广泛的应用与发展，其特点是，标签仅为其中一方所持有（以下称为Guest方），而其他各方拥有数据的部分特征（以下称为Host方）。Guest方希望通过与Host方的合作来提升模型的效果，达到降低风险的目的。在此过程中，Guest方和Host方均需要保证己方的数据安全性。


### SecureBoost

在风控场景中，树模型由于其具备良好的可解释性和强大的学习能力被广泛应用。以Secureboost为代表的递归联邦学习模型，其原理是通过M步的boosting构建M个子模型f_1,…,f_M, 这M个子模型的构建是使用逐步提升的方法，在第m步时，f_1,…,f_(m-1)这m-1个子模型已经建立，f_m的建立目标是最小化损失函数：

obj^((m))=∑_(i=1)^n▒〖Loss(y_i,y ̂_i^((m-1) )+f_m (x_i))〗+Ω(f_m )+constant, 

其中y ̂^((m-1))=∑_(j=1)^(m-1)▒〖f_j (x_i ) 〗  为前面已经构建的由m-1个随机森林组成的模型的输出，y ̂_i^((m-1) )为向量y ̂^((m-1))的第i个值，{x_i:i=1,…,n}为训练数据集，Loss(y_i,y ̂_i)为损失函数，如均方误差(MSE)损失函数为Loss_MSE (y_i,y ̂_i )=1/2 (y_i-y ̂_i )^2。
将XGBoost扩展到纵向联邦场景下，为了保护数据的隐私与安全，SecureBoost方法被提出，提供了一种安全地构建梯度提升树模型的思路。它包含了两个过程，首先对样本进行加密对齐，其次进行加密的模型训练，一个典型的纵向联邦梯度提升决策树模型建模流程如图1所示：

第一阶段  加密样本对齐
由于训练算法需要各参与方将属于同一条数据的特征对应起来，为了保护数据隐私与安全，框架基于隐私求交技术将数据样本对齐。

第二阶段  加密模型训练
在第二阶段，基于对齐后的数据利用各参与方的数据进行联邦建模。中间数据通过同态加密算法（如Pailllier）来保护中间值的安全性，防止泄露数据隐私。建立梯度提升树模型的关键在于1）第t棵树的构建是以第t-1次的标签残差为目标进行学习的；2）每棵树的构建中，决定每个节点如何分裂、是否分裂，这一过程是由多方合作、信息交换计算出每个特征在每个阈值分裂后的得分，取最大得分的结果进行分裂来实现的。
Guest方算出对于每个m-1次迭代后的预测值y ̂^((m-1))（初始为0）的一阶导数g_i和二阶导数h_i，对g和h进行同态加密后传输给每一个Host方。Host利用公钥计算出每个特征每个分裂的一阶导数求和和二阶导数求和并发送给Guest方解密；Guest则直接计算每个特征每个分裂梯度聚合值明文。
Guest方根据得到的所有的一阶导数和二阶导数聚合值算出每个特征每种分裂的得分，如果最大得分小于阈值γ则不分裂。否则按照相应属性和阈值分裂当前节点，得到对应的两个叶子节点和各自的样本id集合I_L和I_R。对于第m棵树的每一个叶子节点，循环执行以上，直到所有的叶子节点不能再分裂或者树的深度达到设置的最大深度为止，Guest方计算出每个叶子节点的最优权重w_i，则第m棵树构建完成。
由此联邦学习过程可知，在建模过程中，Guest方和Host方无法获知对方的数据信息，保证了各参与方的数据安全。同时，每棵树的每个节点构建过程，Guest与Host需要通过大量的加密文通讯找到最优分裂特征信息，大大增加联邦模型的通讯成本。


### 隐私保护

   

### 可解释性要求



### 效率与有效性

   

### Our Consideration

